{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27875c17",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2777f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(260)\n",
    "import itertools\n",
    "\n",
    "# Path to musicImagery dataset\n",
    "dataDir = r'../../data/musicImagery/'\n",
    "#dataDir = r'D:\\marion_music_imagery\\datasetCND_musicImagery\\musicImagery'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f5d76b",
   "metadata": {},
   "source": [
    "# Load stimuli\n",
    "Note: ```stimIndxs``` range from 1 to 4 and ```condIdxs``` range from 1-2.\n",
    "These are _not_ 0-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760070e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_mat = loadmat(dataDir+r\"/dataCND/dataStim.mat\", simplify_cells = True) \n",
    "stim = stim_mat['stim']\n",
    "# print(stim)\n",
    "\n",
    "stimIdxs = stim['stimIdxs']\n",
    "print(f'stimIdxs shape (N trials): {stimIdxs.shape}')\n",
    "\n",
    "condIdxs = stim['condIdxs']\n",
    "print(f'condIdxs shape (N trials): {condIdxs.shape}')\n",
    "\n",
    "condNames = stim['condNames']\n",
    "print(f'condNames shape (P conditions): {condNames.shape}')\n",
    "\n",
    "stim_events = stim['data']\n",
    "print(f'events shape (M features, N trials): {stim_events.shape}')\n",
    "\n",
    "stim_event_labels = stim['names']\n",
    "print(f'event names shape (M features): {stim_event_labels.shape}')\n",
    "\n",
    "fs_stim = stim['fs'] # ignore, use fs from data struct (64 Hz)\n",
    "print(f'fs: {fs_stim} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a238bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy mapping of indices to labels\n",
    "stimId_to_Song_map = {\n",
    "    2: 'chor-038', \n",
    "    1: 'chor-096', \n",
    "    3: 'chor-101',\n",
    "    4: 'chor-019', \n",
    "} # from read_stim_midi.ipynb\n",
    "\n",
    "stimLabel_to_id_map = {\n",
    "    'chor-038': 2, \n",
    "    'chor-096': 1, \n",
    "    'chor-101': 3,\n",
    "    'chor-019': 4, \n",
    "} # reverse mapping\n",
    "\n",
    "stimLabel_to_sheet_order_map = {\n",
    "    'chor-038': 1, \n",
    "    'chor-096': 2, \n",
    "    'chor-101': 3,\n",
    "    'chor-019': 4, \n",
    "} # order of songs on sheet music\n",
    "\n",
    "condId_to_State_map = {\n",
    "    1: 'Listening', \n",
    "    2: 'Imagery'\n",
    "} # from condNames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70aa3d12",
   "metadata": {},
   "source": [
    "# Stim Channel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f37c61e7",
   "metadata": {},
   "source": [
    "Finding tactile metronome onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57694c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Guilhem's note\n",
    "barOnsets = [1, 157] # in sample indices\n",
    "\n",
    "cueTime = 310 # third bar\n",
    "for barIdx in range(10): # 12 bars total\n",
    "    barOnsets.append(cueTime)\n",
    "    if barIdx%2 == 1:\n",
    "        cueTime += 153\n",
    "    else:\n",
    "        cueTime += 154\n",
    "        \n",
    "cueTime -= 1 # index from 0\n",
    "\n",
    "# Make a new exp vector for metronome hits\n",
    "cueExp = np.zeros_like(stim_events[1][0]) # same size as the first expectation vector\n",
    "cueExp[barOnsets] = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.stem(cueExp, '*')\n",
    "plt.xlabel('Time [sample]')\n",
    "plt.title('Tactle Metronome Onsets')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6e5c9dd",
   "metadata": {},
   "source": [
    "Note onsets for stim channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = {}\n",
    "for stimLabel in [\n",
    "    'chor-038', \n",
    "    'chor-096', \n",
    "    'chor-101',\n",
    "    'chor-019']: # top to bottom on the sheet music\n",
    "\n",
    "    stim[stimLabel] = {}\n",
    "    \n",
    "    # Collect note and beat onsets for current stim\n",
    "    stimIdx = stimLabel_to_id_map[stimLabel]\n",
    "    stimExp = stim_events[1][11*(stimIdx-1)] # expectations vector for current stim\n",
    "    note_onsets = stimExp > 0\n",
    "    stim[stimLabel]['notes'] = note_onsets\n",
    "    stim[stimLabel]['beats'] = cueExp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96c46d1e",
   "metadata": {},
   "source": [
    "These indices will be used later to identify song and condition for a given subject's trial order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect stim idxs by condition and song\n",
    "idxs = {} # dict to store idxs for each condition and stim/song idx\n",
    "\n",
    "for condIdx in np.unique(condIdxs): # two conditions\n",
    "    condName = condNames[condIdx-1] # MATLAB indexes from 1...\n",
    "    idxs[condName] = {}\n",
    "    \n",
    "    for stimIdx in np.unique(stimIdxs):\n",
    "        \n",
    "        stimName = stimId_to_Song_map[stimIdx]\n",
    "        \n",
    "        print(f'{condName}: Song {stimName}: Indices:') \n",
    "        matched_ndx = np.where(\n",
    "            (stimIdxs == stimIdx) & (condIdxs == condIdx)\n",
    "            )[0]\n",
    "        print(matched_ndx)\n",
    "        \n",
    "        idxs[condName][stimName] = matched_ndx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2f2fb03",
   "metadata": {},
   "source": [
    "# Load EEG data for all subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d708dfe",
   "metadata": {},
   "source": [
    "Load pre-processed blink data for multiple subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf715f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_peaks_filename = '../../data/eog_peaks/eog_peaks_21subs.npy'\n",
    "eog_peaks = np.load(eog_peaks_filename, allow_pickle=True)\n",
    "eog_peaks = eog_peaks.flat[0]\n",
    "eog_peaks[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192053e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_peaks_merged_trials = {}\n",
    "fs_Hz = 64.0\n",
    "\n",
    "for subjectID in range(1, 21+1):\n",
    "    npy_path = f'../../data/eog_peaks/merged_raws/eog_peaks_sub{subjectID}_merged_raws.npy'\n",
    "    arr = np.load(npy_path, allow_pickle=True)\n",
    "    arr = arr.flat[0]\n",
    "    eog_peaks_merged_trials[subjectID] = arr[subjectID]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef2e0c7d",
   "metadata": {},
   "source": [
    "Replace old eog_peak blinks with eog_peaks_merged_trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef91af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get blinks by trial\n",
    "def getTrialBlinksAndSource(subjectID, trial, eog_peaks_merged_trials, n_trial = 1803):\n",
    "    n_trial_start = trial * n_trial\n",
    "    n_trial_end = (trial + 1) * n_trial\n",
    "    \n",
    "    ica_eog_events = eog_peaks_merged_trials[subjectID]['ica_eog_events']\n",
    "    #print(ica_eog_events)\n",
    "    \n",
    "    trial_blinks = ica_eog_events[\n",
    "        (n_trial_start <= ica_eog_events) & (ica_eog_events < n_trial_end)\n",
    "    ]\n",
    "    trial_blinks -= n_trial_start # reset trial start to t=0\n",
    "\n",
    "    source = eog_peaks_merged_trials[subjectID]['source']\n",
    "    trial_source = source[n_trial_start:n_trial_end]\n",
    "\n",
    "    return trial_blinks, trial_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_SOURCE = True\n",
    "OVERWRITE_EOG_PEAKS = True\n",
    "\n",
    "for subjectID in eog_peaks:\n",
    "    if PLOT_SOURCE:\n",
    "        fig, ax = plt.subplots(figsize = (24, 32))\n",
    "\n",
    "    trial = 0\n",
    "    deltas = []\n",
    "    for stimIdx in eog_peaks[subjectID]:\n",
    "        ica_eog_events_old = eog_peaks[subjectID][stimIdx]['ica_eog_events']\n",
    "        source_old = np.copy(eog_peaks[subjectID][stimIdx]['source']) # to prevent modifying in place\n",
    "\n",
    "        ica_eog_events_new, source_new = getTrialBlinksAndSource(\n",
    "            subjectID, \n",
    "            trial, \n",
    "            eog_peaks_merged_trials, \n",
    "            n_trial = 1803,\n",
    "        )\n",
    "        source_new = np.copy(source_new)\n",
    "        \n",
    "        num_blinks_old = len(ica_eog_events_old)\n",
    "        num_blinks_new = len(ica_eog_events_new)\n",
    "        delta = num_blinks_new - num_blinks_old\n",
    "        deltas.append(delta)\n",
    "\n",
    "        if delta != 0:\n",
    "            summary = f'sub{subjectID}\\ttrial{trial}\\tstimIdx{stimIdx}'\n",
    "            summary += f'\\told: {num_blinks_old}\\tnew: {num_blinks_new}\\tdel: {delta}'\n",
    "            print(summary)\n",
    "\n",
    "        if PLOT_SOURCE:\n",
    "            source_old /= np.max(np.abs(source_old))\n",
    "            source_new /= np.max(np.abs(source_new))\n",
    "\n",
    "            line, = ax.plot(\n",
    "                trial - source_old, \n",
    "                label='old',\n",
    "                c = 'k',\n",
    "                alpha = 0.2, \n",
    "                #ls = ':',\n",
    "            )\n",
    "            new_line, = ax.plot(\n",
    "                trial + source_new, \n",
    "                label='new',\n",
    "                #c = line.get_color(),\n",
    "            )\n",
    "            ax.plot(\n",
    "                ica_eog_events_new,\n",
    "                trial + source_new[ica_eog_events_new], \n",
    "                '*',\n",
    "                label='new',\n",
    "                c = new_line.get_color(),\n",
    "            )\n",
    "\n",
    "        if OVERWRITE_EOG_PEAKS:\n",
    "            eog_peaks[subjectID][stimIdx]['ica_eog_events'] = ica_eog_events_new\n",
    "            eog_peaks[subjectID][stimIdx]['source'] = source_new\n",
    "            \n",
    "        trial += 1\n",
    "\n",
    "    if PLOT_SOURCE:\n",
    "        plt.ylabel('Trial #')\n",
    "        plt.xlabel('Sample #')\n",
    "        plt.title(f'Subject: {subjectID}\\nDeltas: {deltas}')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c758cf",
   "metadata": {},
   "source": [
    "Plot top IC (highest EOG score) for all subjects, conditions, songs, and trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c931a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_SCALE = 10\n",
    "AVG_OFFSET = 15\n",
    "\n",
    "if 0:\n",
    "    for subjectID in eog_peaks:\n",
    "\n",
    "        # Make a new figure per subject, song, and condition \n",
    "        plt.figure(figsize=(16, 16))\n",
    "\n",
    "        t = np.arange(start=0, stop=1803, step=1, dtype='float64')\n",
    "\n",
    "        # Container for collecting average across trials\n",
    "        src_avg = [np.zeros_like(t)]*8\n",
    "        N_avg = 11 #len(eog_peaks[subjectID])\n",
    "        \n",
    "        trialOffset = [0]*8\n",
    "\n",
    "        # Plot eog_source traces for each subject, trial\n",
    "        for trialIdx in eog_peaks[subjectID]:\n",
    "\n",
    "            eog_source = eog_peaks[subjectID][trialIdx]['source']\n",
    "            max_peak = np.max(eog_source)\n",
    "            min_peak = np.min(eog_source)\n",
    "            if np.abs(min_peak) > np.abs(max_peak):\n",
    "                eog_source /= min_peak # normalize, flip polarity\n",
    "            else:\n",
    "                eog_source /= max_peak # normalize\n",
    "\n",
    "            stimIdx = stimIdxs[trialIdx]\n",
    "            condIdx = condIdxs[trialIdx]\n",
    "\n",
    "            pltIdx = 4*(condIdx-1) + stimIdx\n",
    "\n",
    "            # Plot Fp1 data for these trials\n",
    "            plt.subplot(4, 2, pltIdx)\n",
    "\n",
    "            # Plot and add an offset for each trial\n",
    "            plt.plot(eog_source + trialOffset[pltIdx-1]) # chan0 is FP1\n",
    "\n",
    "            # Average\n",
    "            src_avg[pltIdx-1] += eog_source / N_avg\n",
    "\n",
    "            trialOffset[pltIdx-1] += 1\n",
    "                \n",
    "        # Also plot notes/beats and add titles\n",
    "        for stimIdx in [1, 2, 3, 4]: # ordering of stim doesn't matter for plotIdx\n",
    "            stimLabel = stimId_to_Song_map[stimIdx]\n",
    "            notes = t[stim[stimLabel]['notes']]\n",
    "            beats = t[stim[stimLabel]['beats']>0]\n",
    "\n",
    "            for condIdx in [1, 2]:\n",
    "                condLabel = condId_to_State_map[condIdx]\n",
    "\n",
    "                pltIdx = 4*(condIdx-1) + stimIdx\n",
    "\n",
    "                # Plot Fp1 data for these trials\n",
    "                plt.subplot(4, 2, pltIdx)\n",
    "\n",
    "                # Plot the average\n",
    "                plt.plot(AVG_SCALE * src_avg[pltIdx-1] + AVG_OFFSET, \n",
    "                        label=f'{AVG_SCALE} x avg')\n",
    "\n",
    "                # draw beat/note onsets\n",
    "                for note in notes:\n",
    "                    plt.axvline(x=note, c='r', linewidth=1, alpha=0.5, linestyle=':')\n",
    "                for beat in beats:\n",
    "                    plt.axvline(x=beat, c='r', linewidth=1, alpha=0.9) #0 * t_bar[beats_bar], '*')\n",
    "\n",
    "                title_str = '' #'='*50 + '\\n'\n",
    "                title_str += f'Subject: {subjectID}\\n'\n",
    "                title_str += f'{condLabel}: {stimLabel}\\n'\n",
    "                title_str += f'Trials: {N_avg}'\n",
    "                plt.title(title_str)\n",
    "\n",
    "                plt.xlabel('Time [Samples]')\n",
    "                plt.ylabel('Trial #')\n",
    "                plt.legend(loc='upper right', prop={'size': 6}) #, bbox_to_anchor=[1.5, 0.5])\n",
    "                #print(title_str)\n",
    "\n",
    "                pltIdx += 1\n",
    "\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69deb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "fs = 64\n",
    "two_pi = 2*np.pi\n",
    "\n",
    "lo_cutoff_Hz = 1\n",
    "hi_cutoff_Hz = 8\n",
    "\n",
    "sos = signal.butter(\n",
    "    N = 2,\n",
    "    Wn = [lo_cutoff_Hz, hi_cutoff_Hz],\n",
    "    btype = 'bandpass',\n",
    "    analog = False,\n",
    "    output = 'sos',\n",
    "    fs = fs,\n",
    ")\n",
    "\n",
    "'''\n",
    "b, a = signal.butter(\n",
    "    N = 2,\n",
    "    Wn = [0.1, 30],\n",
    "    btype = 'bandpass',\n",
    "    analog = False,\n",
    "    output = 'ba',\n",
    "    fs = 64,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Freq response \n",
    "# code from https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html\n",
    "#ω, h = signal.freqs(b, a)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ω, h = signal.sosfreqz(sos)\n",
    "plt.semilogx(ω/two_pi, 20 * np.log10(abs(h)))\n",
    "plt.title('Butterworth filter frequency response')\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.margins(0, 0.1)\n",
    "plt.grid(which='both', axis='both')\n",
    "plt.axvline(100, color='green') # cutoff frequency\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92036268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different BPF settings to try and improve EOG event detection \n",
    "\n",
    "def ica_find_eog_events_custom(raw_trials, subjectID, trialIdx, source, l_freq, h_freq):\n",
    "    \n",
    "    #print(f'[{trialIdx}] from {raw_trials[subjectID]}')\n",
    "    \n",
    "    raw = raw_trials[subjectID][trialIdx-1]\n",
    "\n",
    "    # Find EOG events frop top IC\n",
    "    ica_eog_event_id = 3\n",
    "    ica_eog_events = mne.preprocessing.ica_find_eog_events(\n",
    "        raw,\n",
    "        eog_source = source,\n",
    "        event_id = ica_eog_event_id,\n",
    "        l_freq = l_freq,\n",
    "        h_freq = h_freq,\n",
    "        verbose='ERROR',\n",
    "        #ch_name = ['Fpz', 'Fp1', 'Fp2', 'AF7', 'AF3', 'Afz', 'AF4', 'AF8'],\n",
    "    )\n",
    "\n",
    "    return ica_eog_events\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def find_peaks_from_ica_source(\n",
    "    eog_source,\n",
    "    fs = 64,\n",
    "    height = 0.5,\n",
    "    distance = 32,\n",
    "    bpf = True,\n",
    "    l_freq = 1,\n",
    "    h_freq = 10,\n",
    "    order = 2,\n",
    "):\n",
    "    # Normalize eog source\n",
    "    max_peak = np.max(eog_source)\n",
    "    min_peak = np.min(eog_source)\n",
    "    if np.abs(min_peak) > np.abs(max_peak):\n",
    "        eog_source /= min_peak # normalize, flip polarity\n",
    "    else:\n",
    "        eog_source /= max_peak # normalize\n",
    "\n",
    "    if bpf:\n",
    "        sos = signal.butter(\n",
    "            N = order,\n",
    "            Wn = [l_freq, h_freq],\n",
    "            btype = 'bandpass',\n",
    "            analog = False,\n",
    "            output = 'sos',\n",
    "            fs = fs,\n",
    "        )\n",
    "        eog_source = signal.sosfiltfilt(sos, eog_source)\n",
    "\n",
    "    # Find peaks\n",
    "    ica_eog_events, _ = find_peaks(\n",
    "        eog_source,\n",
    "        height = height, \n",
    "        distance = distance, # could miss double blinks \n",
    "    )\n",
    "\n",
    "    return ica_eog_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a2c082f",
   "metadata": {},
   "source": [
    "# Run peak-finder on top EOG IC\n",
    "TODO: see if this improves blink detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e36f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FILTERED_BLINKS = False\n",
    "\n",
    "if LOAD_FILTERED_BLINKS:\n",
    "    eog_peaks = np.load('eog_peaks_21subs_bpf.npy', allow_pickle=True)\n",
    "    eog_peaks = eog_peaks.flat[0]\n",
    "\n",
    "else:    \n",
    "    CUSTOM_BPF = False\n",
    "    USE_PEAK_FINDER = True\n",
    "    UPDATE_EOG_PEAKS = True\n",
    "\n",
    "    # Plot and add an offset for each trial\n",
    "    t = np.arange(start=0, stop=1803, step=1)\n",
    "\n",
    "    for subjectID in eog_peaks:\n",
    "        \n",
    "        plt.figure(figsize=(8, 48))\n",
    "        pltIdx = 1\n",
    "\n",
    "        # Path to data for selected subject\n",
    "        sub1_mat = loadmat(dataDir+f\"/dataCND/dataSub{subjectID}.mat\", simplify_cells = True) \n",
    "\n",
    "        # Randomized trial order for current subject\n",
    "        orig_trial_pos = sub1_mat['eeg']['origTrialPosition']\n",
    "        #print(f'orig_trial_pos shape: {orig_trial_pos.shape}')\n",
    "\n",
    "        # Get current subject's song and condition ordering (since its randomized)\n",
    "        thisSubStimOrder = stimIdxs[(orig_trial_pos-1)] # convert to being zero indexed\n",
    "        thisSubCondOrder = condIdxs[(orig_trial_pos-1)]\n",
    "        #print(f'Subject{subjectID} stim order: {thisSubStimOrder}')\n",
    "        #print(f'Subject{subjectID} cond order: {thisSubCondOrder}')\n",
    "        \n",
    "\n",
    "        for stimIdx in [1, 2, 3, 4]: # top to bottom on the sheet music\n",
    "            stimLabel = stimId_to_Song_map[stimIdx]\n",
    "\n",
    "            for condIdx in [1, 2]:\n",
    "                condLabel = condId_to_State_map[condIdx]\n",
    "\n",
    "                # Find trials matching this song and condition\n",
    "                trialsToEpoch = np.where(\n",
    "                    (thisSubStimOrder == stimIdx) & (thisSubCondOrder == condIdx)\n",
    "                )[0]\n",
    "\n",
    "                trials_to_plot = trialsToEpoch # idxs[condLabel][stimLabel]\n",
    "\n",
    "                # Plot Fp1 data for these trials\n",
    "                plt.subplot(8, 1, pltIdx)\n",
    "                offset = 0\n",
    "                N_avg = 11\n",
    "                source_avg = np.zeros_like(t, dtype='float64')\n",
    "                \n",
    "                for trialIdx in trials_to_plot:\n",
    "                    source = eog_peaks[subjectID][trialIdx]['source']\n",
    "\n",
    "                    if CUSTOM_BPF == True:\n",
    "                        ica_eog_events = ica_find_eog_events_custom(\n",
    "                            raw_trials, \n",
    "                            subjectID, \n",
    "                            trialIdx, \n",
    "                            source,\n",
    "                            l_freq = 1,\n",
    "                            h_freq = 3,\n",
    "                        )\n",
    "                    elif USE_PEAK_FINDER:\n",
    "                        ica_eog_events = find_peaks_from_ica_source(\n",
    "                            source,    \n",
    "                            height = 0.25,\n",
    "                            distance = 20, # assuming half_width = 10 below\n",
    "                            l_freq = 1,\n",
    "                            h_freq = 8,\n",
    "                            order = 2,\n",
    "                        )\n",
    "                    else:\n",
    "                        ica_eog_events = eog_peaks[subjectID][trialIdx]['ica_eog_events']\n",
    "\n",
    "                    if UPDATE_EOG_PEAKS:\n",
    "                        eog_peaks[subjectID][trialIdx]['ica_eog_events'] = ica_eog_events\n",
    "\n",
    "                    # print(t)\n",
    "\n",
    "                    # plt.plot(fp1_data_hp + offset -1)\n",
    "                    ic_trace, = plt.plot(\n",
    "                        t,\n",
    "                        source + offset,\n",
    "                        linewidth = 0.5,\n",
    "                    )\n",
    "                    \n",
    "                    plt.plot(\n",
    "                        t[ica_eog_events], \n",
    "                        source[ica_eog_events] + offset, \n",
    "                        '*',\n",
    "                        color = ic_trace.get_color())\n",
    "\n",
    "                    offset += 1 # increment offset for next run\n",
    "\n",
    "                    # Average\n",
    "                    source_avg += source / N_avg\n",
    "\n",
    "                # Plot the average\n",
    "                # print(fp1_avg)\n",
    "                offset = 12\n",
    "                plt.plot(10 * source_avg + offset, label='scaled avg')\n",
    "\n",
    "                # Plot the note onsets\n",
    "                plt.plot(offset * note_onsets, 'r', \n",
    "                        label='note', \n",
    "                        alpha=0.2,\n",
    "                        linewidth=1\n",
    "                        ) # 1 = expectations\n",
    "\n",
    "                # Plot metronome hits (could overlap with some notes)\n",
    "                plt.plot(offset * cueExp, \n",
    "                        'r', \n",
    "                        label='bar', \n",
    "                        alpha=0.5,\n",
    "                        linewidth=1\n",
    "                        )\n",
    "\n",
    "                condName = condId_to_State_map[condIdx]\n",
    "                stimName = stimId_to_Song_map[stimIdx]\n",
    "\n",
    "                title_str = '' #'='*50 + '\\n'\n",
    "                title_str += f'Subject {subjectID}: top EOG IC across trials\\n'\n",
    "                title_str += f'Task [{condIdx}]: {condName}\\n'\n",
    "                title_str += f'Stim [{stimIdx}]: {stimName}\\n'\n",
    "                title_str += f'Trials: {trials_to_plot}'\n",
    "                plt.title(title_str)\n",
    "\n",
    "                plt.xlabel('Time [Samples]')\n",
    "                plt.ylabel('Trial #')\n",
    "                plt.legend(loc='upper right', prop={'size': 6}) #, bbox_to_anchor=[1.5, 0.5])\n",
    "                #print(title_str)\n",
    "\n",
    "                pltIdx += 1\n",
    "\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f89806",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILTERED_BLINKS = False\n",
    "if SAVE_FILTERED_BLINKS:\n",
    "    filename = eog_peaks_filename.split('.npy')[0] + '_bpf.npy'\n",
    "    np.save(filename, eog_peaks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8967207c",
   "metadata": {},
   "source": [
    "# Compare blink events before/after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7d8682a",
   "metadata": {},
   "source": [
    "# Convolve with Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b862f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blink_atten( # update to use a convolution\n",
    "        t, \n",
    "        peaks, \n",
    "        half_width\n",
    "    ):\n",
    "    peaks_sq = np.zeros_like(t)\n",
    "    for peak in peaks:\n",
    "        start_ndx = peak-half_width\n",
    "        stop_ndx = peak+half_width\n",
    "        if start_ndx < 0:\n",
    "            start_ndx = 0\n",
    "        if stop_ndx > len(t):\n",
    "            stop_ndx = len(t)\n",
    "        peaks_sq[start_ndx : stop_ndx] += 1\n",
    "    return peaks_sq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "266dbbcf",
   "metadata": {},
   "source": [
    "Plot rectangular eye blink train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    NOTES_Y_OFFSET = 12\n",
    "\n",
    "    half_width = 10\n",
    "\n",
    "    t = np.arange(start=0, stop=len(cueExp), step=1)\n",
    "\n",
    "    peaks_sq_all = {}\n",
    "    for subjectID in eog_peaks:\n",
    "        peaks_sq_all[subjectID] = {}\n",
    "        \n",
    "        for stimIdx in [1, 2, 3, 4]: # top to bottom on the sheet music\n",
    "            stimLabel = stimId_to_Song_map[stimIdx]\n",
    "            peaks_sq_all[subjectID][stimLabel] = {}\n",
    "            \n",
    "            notes = t[stim[stimLabel]['notes']]\n",
    "            beats = t[stim[stimLabel]['beats']>0]\n",
    "\n",
    "            for condIdx in [1, 2]:\n",
    "                condLabel = condId_to_State_map[condIdx]\n",
    "                peaks_sq_all[subjectID][stimLabel][condLabel] = {}\n",
    "\n",
    "                trials_to_plot = idxs[condLabel][stimLabel]\n",
    "                    \n",
    "                plt.figure(figsize=(8, 4))\n",
    "\n",
    "                plt.plot(t[notes], 0*t[notes] + NOTES_Y_OFFSET, '.', label='notes')\n",
    "                plt.plot(t[beats], 0*t[beats] + NOTES_Y_OFFSET, 'o', label='beats')\n",
    "\n",
    "                trialCnt = 0\n",
    "                for trialIdx in trials_to_plot:\n",
    "                    peaks = eog_peaks[subjectID][trialIdx]['ica_eog_events']\n",
    "                    peaks_sq = blink_atten(t, peaks, half_width)\n",
    "                    \n",
    "                    peaks_sq_all[subjectID][stimLabel][condLabel][trialIdx] = peaks_sq\n",
    "\n",
    "                    #plt.plot(t, peaks_sq_rot + trialCnt)\n",
    "                    line, = plt.plot(t, peaks_sq/2 + trialCnt)\n",
    "                    plt.plot(t[peaks], 0*t[peaks] + trialCnt + 0.5, 'x', c=line.get_color())\n",
    "                    plt.plot(t[peaks], 0*t[peaks] + trialCnt + 0.5, 'x', c=line.get_color())\n",
    "\n",
    "                    trialCnt += 1\n",
    "\n",
    "                plt.xlabel('Time [sample]')\n",
    "                plt.ylabel('Trial #')\n",
    "                plt.legend(loc='upper right')\n",
    "                title_str = f'Subject{subjectID} | {condLabel} | {stimLabel}'\n",
    "                plt.title(title_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d1bbffd",
   "metadata": {},
   "source": [
    "Examine eog_peaks structure as loaded from .npy object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca274b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 1 # [1, 3, 7, 11]\n",
    "condLabel = 'Imagery'\n",
    "stimLabel = 'chor-019'\n",
    "\n",
    "trials = idxs[condLabel][stimLabel] # [2, 8, 14, 15, 26, 27, 29, 36, 47, 48, 52, 3, 6, 11, 28, 33, 34, 37, 51, 58, 62, 70, 7, 10, 21, 23, 30, 35, 38, 39, 66, 74, 86, 12, 17, 24, 44, 45, 49, 54, 55, 56, 64, 76, 18, 19, 31, 32, 41, 57, 61, 69, 79, 84, 87, 1, 25, 42, 43, 46, 59, 60, 67, 68, 73, 85, 0, 13, 16, 22, 40, 63, 71, 75, 77, 78, 83, 4, 5, 9, 20, 50, 53, 65, 72, 80, 81, 82])\n",
    "\n",
    "for trial in trials:\n",
    "    blinks = eog_peaks[sub][trial]['ica_eog_events']\n",
    "    print(trial, blinks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be306b8",
   "metadata": {},
   "source": [
    "## Read in images of the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541dfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib as mpl \n",
    "\n",
    "    # from stackexchange\n",
    "    imgs = {}\n",
    "\n",
    "    start_px = 50\n",
    "    for bar in range(8):\n",
    "        img = mpimg.imread('data/Score.png')\n",
    "        \n",
    "        stop_px = start_px + 70\n",
    "        imgs[bar] = img[start_px:stop_px, 10:-15].copy()\n",
    "        \n",
    "        # offset to the next bar\n",
    "        start_px += 100\n",
    "        if bar%2 == 1:\n",
    "            start_px += 100\n",
    "            \n",
    "    %matplotlib widget \n",
    "\n",
    "    for bar in range(8):\n",
    "        plt.figure()\n",
    "        plt.imshow(imgs[bar])\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fad846e",
   "metadata": {},
   "source": [
    "# Info Theory Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a842ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condId_to_State_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimLabel_to_id_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_cost(\n",
    "        p, q,\n",
    "        SMALL_NUMBER = 1e-20, #np.nextafter(0, 1)\n",
    "        SQ_SANITY_CHECK = False,\n",
    "        NORM = 'sum',\n",
    "    ):\n",
    "    p += SMALL_NUMBER\n",
    "    q += SMALL_NUMBER\n",
    "\n",
    "    if NORM == 'sum':\n",
    "        #print(f'p: {p.shape}, q: {q.shape}')\n",
    "        p /= np.sum(p) # normalize the area\n",
    "        q /= np.sum(q) # normalize the area\n",
    "    elif NORM == 'max':\n",
    "        p /= np.max(p) # normalize the area\n",
    "        q /= np.max(q) # normalize the area\n",
    "    elif NORM == 'none':\n",
    "        p /= 1\n",
    "        q /= 1\n",
    "\n",
    "        if 0:\n",
    "            p[(1-p)<SMALL_NUMBER] -= SMALL_NUMBER # if any p_i == 1, make it slightly smaller to prevent division by log(1) = 0\n",
    "            q[(1-q)<SMALL_NUMBER] -= SMALL_NUMBER # if any q_i == 1, make it slightly smaller to prevent division by log(1) = 0\n",
    "            \n",
    "            p[p<SMALL_NUMBER] += SMALL_NUMBER # if any p_i == 0, make it slightly bigger to prevent division by log(1) = 0\n",
    "            q[q<SMALL_NUMBER] += SMALL_NUMBER # if any q_i == 0, make it slightly bigger to prevent division by log(1) = 0\n",
    "    \n",
    "    # Rescale to 0-1\n",
    "    if 0:\n",
    "        norm_factor = np.max(\n",
    "            (np.abs(p), np.abs(q))\n",
    "        )\n",
    "        p /= norm_factor\n",
    "        q /= norm_factor\n",
    "\n",
    "    info = 0\n",
    "    for i in range(len(p)):\n",
    "        p_i = p[i]\n",
    "        q_i = q[i] \n",
    "        if SQ_SANITY_CHECK:\n",
    "            info += (p_i - q_i)**2\n",
    "        else:\n",
    "            info += -q_i * np.log2(p_i, where=p_i>0) \n",
    "            info += -(1-q_i)*np.log2(1-p_i, where=(1-p_i)>0)\n",
    "    \n",
    "    info /= len(p)\n",
    "    return info, p, q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53ef5557",
   "metadata": {},
   "source": [
    "$$\n",
    "qlog(p) + (1-q)log(p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "plog(q) + (1-p)log(q)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bec39138",
   "metadata": {},
   "source": [
    "# Duration of a quarter note in #samples (for timescales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb51bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = 100\n",
    "bps = bpm/60\n",
    "n_quarter_note = int(bps*fs)\n",
    "print(n_quarter_note)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f97a709",
   "metadata": {},
   "source": [
    "# Split training ($p$) and test ($q$) trials\n",
    "\n",
    "To Do:\n",
    "- Split p/q 5:5, keep one trial aside for decoding testing\n",
    "- Compare coding cost against a uniform p (flat blink prob across of 1/1803)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DISTROS = False # True # visualize p and q distros\n",
    "SQ_SANITY_CHECK = False \n",
    "\n",
    "NUM_SUBJECTS = len(eog_peaks)\n",
    "TEST_STIM_LABELS = ['chor-038', 'chor-096', 'chor-101', 'chor-019']\n",
    "condLabels = ['Listening', 'Imagery'] #['Listening'] # consider only listening\n",
    "\n",
    "NUM_TRAINING_TRIALS = 6 #10\n",
    "\n",
    "TIMESCALES = [\n",
    "    n_quarter_note/4,   # 1/16\n",
    "    n_quarter_note/2,   # 1/8\n",
    "    n_quarter_note,     # 1/4\n",
    "    n_quarter_note*2,   # 1/2\n",
    "    n_quarter_note*4,   # 1\n",
    "    n_quarter_note*8,   # 2\n",
    "    n_quarter_note*16,   # 4\n",
    "]\n",
    "half_width_sweep = [] #collects corresponding half width durations\n",
    "\n",
    "t = np.arange(start=0, stop=len(cueExp), step=1)\n",
    "\n",
    "AVG_LOOPS = 1\n",
    "train_trial_avg = {}\n",
    "test_trial_avg = {} # data for test set?\n",
    "\n",
    "for n_loop in range(AVG_LOOPS):\n",
    "    for n_note in TIMESCALES:\n",
    "        \n",
    "        half_width = int(n_note/2)\n",
    "        half_width_sweep.append(half_width)\n",
    "        \n",
    "        if not half_width in train_trial_avg:\n",
    "            train_trial_avg[half_width] = {}\n",
    "            test_trial_avg[half_width] = {}\n",
    "\n",
    "        if PLOT_DISTROS:\n",
    "            plt.figure(figsize = (20, 6*NUM_SUBJECTS))\n",
    "            pltIdx = 0\n",
    "\n",
    "        for subjectID in eog_peaks.keys(): #allTrialsForNullDistro:\n",
    "            if not subjectID in train_trial_avg[half_width]:\n",
    "                train_trial_avg[half_width][subjectID] = {}\n",
    "                test_trial_avg[half_width][subjectID] = {}\n",
    "\n",
    "            for condLabel in condLabels:\n",
    "                if not condLabel in train_trial_avg[half_width][subjectID]:\n",
    "                    train_trial_avg[half_width][subjectID][condLabel] = {}\n",
    "                    test_trial_avg[half_width][subjectID][condLabel] = {}\n",
    "                \n",
    "                for stimLabel in TEST_STIM_LABELS:\n",
    "                    if not stimLabel in train_trial_avg[half_width][subjectID][condLabel]:\n",
    "                        train_trial_avg[half_width][subjectID][condLabel][stimLabel] = {}\n",
    "                        test_trial_avg[half_width][subjectID][condLabel][stimLabel] = {}\n",
    "\n",
    "                    if not n_loop in train_trial_avg[half_width][subjectID][condLabel][stimLabel]:\n",
    "                        train_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop] = np.zeros_like(t, dtype=np.float64)\n",
    "                        test_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop] = np.zeros_like(t, dtype=np.float64)\n",
    "\n",
    "                    # Split trials into train-test sets\n",
    "                    allMatchingTrials = [x for x in idxs[condLabel][stimLabel]] #peaks_sq_all[subjectID][stimLabel][condLabel].keys()]\n",
    "                    allMatchingTrials = np.array(allMatchingTrials)\n",
    "                    np.random.shuffle(allMatchingTrials)\n",
    "                    \n",
    "                    #print('All trials:', allMatchingTrials)\n",
    "                    trainTrialIdxs = allMatchingTrials[:NUM_TRAINING_TRIALS]\n",
    "                    print('Train trials:', trainTrialIdxs)\n",
    "                    testTrialIdxs = allMatchingTrials[NUM_TRAINING_TRIALS:]\n",
    "                    print('Test trials:', testTrialIdxs)\n",
    "\n",
    "                    # Get the distro for training trials\n",
    "                    for trainTrial in trainTrialIdxs:\n",
    "                        train_peaks = eog_peaks[subjectID][trainTrial]['ica_eog_events']\n",
    "                        train_peaks_sq = blink_atten(t, train_peaks, half_width)\n",
    "                        train_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop] += train_peaks_sq / NUM_TRAINING_TRIALS\n",
    "\n",
    "\n",
    "                    # Now get the distro for test trials\n",
    "                    for testTrial in testTrialIdxs:\n",
    "                        test_peaks = eog_peaks[subjectID][testTrial]['ica_eog_events']\n",
    "                        test_peaks_sq = blink_atten(t, test_peaks, half_width)\n",
    "                        #val_peaks_sq = peaks_sq_all[subjectID][stimLabel][condLabel][testTrial]\n",
    "                        test_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop] += test_peaks_sq / len(testTrialIdxs)\n",
    "\n",
    "                    if PLOT_DISTROS:\n",
    "                        notes = t[stim[stimLabel]['notes']]\n",
    "                        beats = t[stim[stimLabel]['beats']>0]\n",
    "                        \n",
    "                        p = np.copy(train_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop])\n",
    "                        q = np.copy(test_trial_avg[half_width][subjectID][condLabel][stimLabel][n_loop])\n",
    "                        info = coding_cost(p, q, SQ_SANITY_CHECK=SQ_SANITY_CHECK)\n",
    "\n",
    "                        pltIdx += 1\n",
    "                        ax = plt.subplot(len(eog_peaks.keys()) * len(condLabels), 4, pltIdx)\n",
    "\n",
    "                        train_line, = ax.plot(\n",
    "                            t/fs, \n",
    "                            #peaks_sq_baseline, \n",
    "                            p,\n",
    "                            #'.', \n",
    "                            label=f'Training avg.', \n",
    "                            c='k',\n",
    "                            linewidth=1,\n",
    "                            #alpha=0.1,\n",
    "                        )\n",
    "\n",
    "                        test_line, = ax.plot(\n",
    "                            t/fs, \n",
    "                            #test_trial_avg[subjectID][stimLabel], \n",
    "                            q, \n",
    "                            #'.', \n",
    "                            label=f'Test avg.', \n",
    "                            c='r',\n",
    "                            linewidth=1,\n",
    "                            #alpha=0.1,\n",
    "                        )\n",
    "\n",
    "                        title_str = 'Blink Dur: {:.3f} s'.format(2 * half_width * 1/fs)\n",
    "                        title_str+= f', sub-{subjectID}, {condLabel}, {stimLabel}'\n",
    "                        title_str+= f'\\nTraining Trials\\t(for $p_i$): {trainTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                        title_str+= f'\\nTest Trials\\t(for $q_i$): {testTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                        if SQ_SANITY_CHECK:\n",
    "                            title_str+= '\\n$ 1/N \\sum (p_i - q_i)^2$ = {:.5f}'.format(info)\n",
    "                        else:\n",
    "                            title_str+= '\\n$-1/N \\sum q_i log p_i + (1-q_i) log (1-p_i)$ = {:.5f}'.format(info)\n",
    "                        ax.set_title(title_str)\n",
    "\n",
    "                        ax.set_xlabel('Time [s]')\n",
    "                        #ax.set_ylim([0, .01])\n",
    "\n",
    "    if PLOT_DISTROS:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_info(results_matrix, ax, rowLabels, colLabels, title= \"\", vmin = None, vmax=None, fontsize=4, cmap='magma'):\n",
    "    # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    # fig, ax = plt.subplots(figsize = figsize)\n",
    "    im = ax.imshow(results_matrix, cmap=cmap, interpolation=None, vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax.set_xticks(np.arange(len(colLabels)), labels=colLabels)\n",
    "    ax.set_yticks(np.arange(len(rowLabels)), labels=rowLabels)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=fontsize)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "            rotation_mode=\"anchor\", fontsize=fontsize)\n",
    "    '''\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            text = ax.text(j, i, results_matrix[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "    '''\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "def plot_pq(ax, p, q, t, fs, title_str = ''):\n",
    "    #ax = plt.subplot(len(eog_peaks.keys()) * len(condLabels), 4, pltIdx)\n",
    "\n",
    "    train_line, = ax.plot(\n",
    "        t/fs, \n",
    "        #peaks_sq_baseline, \n",
    "        p,\n",
    "        #'.', \n",
    "        label=f'p', \n",
    "        c='k',\n",
    "        linewidth=1,\n",
    "        #alpha=0.1,\n",
    "    )\n",
    "\n",
    "    test_line, = ax.plot(\n",
    "        t/fs, \n",
    "        #test_trial_avg[subjectID][stimLabel], \n",
    "        q, \n",
    "        #'.', \n",
    "        label=f'q', \n",
    "        c='r',\n",
    "        linewidth=1,\n",
    "        #alpha=0.1,\n",
    "    )\n",
    "    #ax.legend()\n",
    "    ax.set_title(title_str)\n",
    "    ax.set_xlabel('Time [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimId_to_Song_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4733c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trial_avg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaccdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_width_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d768610",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PQ = not True\n",
    "\n",
    "subjectIDs = [1, 6, 7, 11, 17]\n",
    "half_widths = [13, 26] #, 53, 106]\n",
    "condLabels = ['Listening', 'Imagery'] #list(train_trial_avg[half_widths[0]][subjectIDs[0]].keys())\n",
    "stimLabels = list(train_trial_avg[half_widths[0]][subjectIDs[0]][condLabels[0]].keys())\n",
    "NORMS = ['sum'] #, 'none'] #['sum'] #, 'max']\n",
    "sq_checks = [False] #[True, False]\n",
    "P_BASELINE_CHECK = [True, False]\n",
    "P_TRAIN = True\n",
    "\n",
    "for P_BASELINE in P_BASELINE_CHECK:\n",
    "    for SQ_SANITY_CHECK in sq_checks:\n",
    "        for Q_TRAIN in [False]: #[True, False]:\n",
    "            for half_width in half_widths:\n",
    "                for NORM in NORMS:\n",
    "                    \n",
    "                    rowLabels = []\n",
    "                    colLabels = []\n",
    "\n",
    "                    N = len(subjectIDs)*len(condLabels)*len(stimLabels)\n",
    "                    results_matrix = np.zeros(\n",
    "                        shape=(N, N),\n",
    "                    )\n",
    "                    p_norms = {}\n",
    "                    q_norms = {}\n",
    "\n",
    "                    for i in range(N):\n",
    "                        p_norms[i] = {}\n",
    "                        q_norms[i] = {}\n",
    "\n",
    "                        for j in range(N):\n",
    "\n",
    "                            subjectID1 = subjectIDs[int(i / (len(condLabels)*len(stimLabels)))]\n",
    "                            subjectID2 = subjectIDs[int(j / (len(condLabels)*len(stimLabels)))]\n",
    "\n",
    "                            condLabel1 = condId_to_State_map[1 + int(i / len(stimLabels))%len(condLabels)]\n",
    "                            condLabel2 = condId_to_State_map[1 + int(j / len(stimLabels))%len(condLabels)]\n",
    "\n",
    "                            stimLabel1 = stimId_to_Song_map[1 + i % len(stimLabels)] #% (len(subjectIDs)*len(condLabels))]\n",
    "                            stimLabel2 = stimId_to_Song_map[1 + j % len(stimLabels)] #% (len(subjectIDs)*len(condLabels))]\n",
    "\n",
    "                            if i == 0:\n",
    "                                colLabels.append(f'{subjectID2} / {condLabel2} / {stimLabel2}')\n",
    "\n",
    "\n",
    "                            p_norms[i][j] = np.zeros_like(t, dtype=np.float64)\n",
    "                            q_norms[i][j] = np.zeros_like(t, dtype=np.float64)\n",
    "                            \n",
    "                            for n_loop in range(AVG_LOOPS):\n",
    "                                if P_BASELINE:\n",
    "                                    p = np.ones_like(t)/len(t)\n",
    "                                else: \n",
    "                                    if P_TRAIN:\n",
    "                                        p = train_trial_avg[half_width][subjectID1][condLabel1][stimLabel1][n_loop]\n",
    "                                    else:\n",
    "                                        p = test_trial_avg[half_width][subjectID1][condLabel1][stimLabel1][n_loop]\n",
    "\n",
    "                                if Q_TRAIN:\n",
    "                                    q = train_trial_avg[half_width][subjectID2][condLabel2][stimLabel2][n_loop]\n",
    "                                else:\n",
    "                                    q = test_trial_avg[half_width][subjectID2][condLabel2][stimLabel2][n_loop]\n",
    "\n",
    "                                cost, p_norm, q_norm = coding_cost(\n",
    "                                    np.copy(p), \n",
    "                                    np.copy(q), \n",
    "                                    SMALL_NUMBER=1e-20,\n",
    "                                    SQ_SANITY_CHECK=SQ_SANITY_CHECK,\n",
    "                                    NORM=NORM,\n",
    "                                ) \n",
    "                                #print(sum(p_norm), sum(q_norm)) # verified approx 1\n",
    "                                results_matrix[i, j] += cost / AVG_LOOPS\n",
    "                                p_norms[i][j] += p_norm / AVG_LOOPS\n",
    "                                q_norms[i][j] += q_norm / AVG_LOOPS\n",
    "\n",
    "                                #print(f'{subjectID1}/{condLabel1}/{stimLabel1} vs. {subjectID2}/{condLabel2}/{stimLabel2}\\t{results_matrix[i, j]}\\t{p}\\t{q}')\n",
    "\n",
    "                        # update after IDs have been calculated above:\n",
    "                        rowLabels.append(f'{subjectID1} / {condLabel1} / {stimLabel1}')\n",
    "\n",
    "                    title = 'Blink Time: {:.3f} ms = {:.2f} qtr notes @ 100 bpm'.format(\n",
    "                        (2 * half_width / fs)*1000,\n",
    "                        (2 * half_width / fs) / (1/bps),\n",
    "                    )\n",
    "                    title += f'\\nNorm by {NORM}\\n'\n",
    "                    \n",
    "                    if SQ_SANITY_CHECK:\n",
    "                        title += 'coding cost: sq'\n",
    "                    else:\n",
    "                        title += 'coding cost: log'\n",
    "                    title += '\\n'\n",
    "\n",
    "                    if P_BASELINE:\n",
    "                        title += 'p: baseline, $\\sum$p = {:.2f}\\n'.format(sum(p_norm))\n",
    "                    else:\n",
    "                        if P_TRAIN:\n",
    "                            title += f'p [{NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: train'\n",
    "                        else:\n",
    "                            title += f'p [{11-NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: test'\n",
    "                        title += '\\n'\n",
    "                    \n",
    "                    if Q_TRAIN:\n",
    "                        title += f'q [{NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: train'\n",
    "                    else:\n",
    "                        title += f'q [{11-NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: test'\n",
    "                    \n",
    "                    figsize = (N*0.4, N*0.4/2)\n",
    "\n",
    "                    fig, ax = plt.subplots(figsize=figsize)\n",
    "                    plot_info(results_matrix,\n",
    "                            ax, \n",
    "                            rowLabels, colLabels, title, \n",
    "                            vmin=0,\n",
    "                            vmax=0.05, #10,\n",
    "                            fontsize = 10,\n",
    "                            )\n",
    "                    \n",
    "                    if PLOT_PQ:\n",
    "                        fig, axs = plt.subplots(N, N, figsize=figsize, sharex=True, sharey=True)\n",
    "\n",
    "                        for i in range(N):\n",
    "                            for j in range(N):\n",
    "                                title_str = 'Blink Dur: {:.3f} s'.format(2 * half_width * 1/fs)\n",
    "                                title_str+= f', sub-{subjectID}, {condLabel}, {stimLabel}'\n",
    "                                title_str+= f'\\nTraining Trials\\t(for $p_i$): {trainTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                                title_str+= f'\\nTest Trials\\t(for $q_i$): {testTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                                if SQ_SANITY_CHECK:\n",
    "                                    title_str+= '\\n$ 1/N \\sum (p_i - q_i)^2$ = {:.5f}'.format(results_matrix[i, j])\n",
    "                                else:\n",
    "                                    title_str+= '\\n$-1/N \\sum q_i log p_i + (1-q_i) log (1-p_i)$ = {:.5f}'.format(results_matrix[i, j])\n",
    "\n",
    "                                plot_pq(axs[i][j], p_norms[i][j], q_norms[i][j], t, fs)\n",
    "                        plt.tight_layout()\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PQ = False\n",
    "\n",
    "subjectIDs = [1, 6, 7, 11, 17] #[1, 3, 7, 11]\n",
    "half_widths = [13, 26] #, 53, 106]\n",
    "condLabels = ['Listening', 'Imagery'] #list(train_trial_avg[half_widths[0]][subjectIDs[0]].keys())\n",
    "stimLabels = list(train_trial_avg[half_widths[0]][subjectIDs[0]][condLabels[0]].keys())\n",
    "NORMS = ['sum'] #, 'none'] #['sum'] #, 'max']\n",
    "sq_checks = [False] #[True, False]\n",
    "P_BASELINE_CHECK = [True, False]\n",
    "P_TRAIN = True\n",
    "\n",
    "for P_BASELINE in P_BASELINE_CHECK:\n",
    "    for SQ_SANITY_CHECK in sq_checks:\n",
    "        for Q_TRAIN in [False]: #[True, False]:\n",
    "            for half_width in half_widths:\n",
    "                for NORM in NORMS:\n",
    "                    rowLabels = []\n",
    "                    colLabels = []\n",
    "\n",
    "                    N = len(subjectIDs)*len(condLabels)*len(stimLabels)\n",
    "                    results_matrix = np.zeros(\n",
    "                        shape=(N, N),\n",
    "                    )\n",
    "                    p_norms = {}\n",
    "                    q_norms = {}\n",
    "\n",
    "                    for i in range(N):\n",
    "                        p_norms[i] = {}\n",
    "                        q_norms[i] = {}\n",
    "\n",
    "                        for j in range(N):\n",
    "                            subjectID1 = subjectIDs[i % len(subjectIDs)] #[int(i / (len(condLabels)*len(stimLabels)))]\n",
    "                            subjectID2 = subjectIDs[j % len(subjectIDs)] #[int(j / (len(condLabels)*len(stimLabels)))]\n",
    "                            condLabel1 = condId_to_State_map[1 + int(i / len(stimLabels))%len(condLabels)]\n",
    "                            condLabel2 = condId_to_State_map[1 + int(j / len(stimLabels))%len(condLabels)]\n",
    "                            stimLabel1 = stimId_to_Song_map[1 + int(i / (len(condLabels)*len(subjectIDs)))] #[1 + (i % 4)]\n",
    "                            stimLabel2 = stimId_to_Song_map[1 + int(j / (len(condLabels)*len(subjectIDs)))] #[1 + (j % 4)]\n",
    "\n",
    "                            if i == 0:\n",
    "                                colLabels.append(f'{subjectID2} / {condLabel2} / {stimLabel2}')\n",
    "\n",
    "\n",
    "                            p_norms[i][j] = np.zeros_like(t, dtype=np.float64)\n",
    "                            q_norms[i][j] = np.zeros_like(t, dtype=np.float64)\n",
    "                            \n",
    "                            for n_loop in range(AVG_LOOPS):\n",
    "                                if P_BASELINE:\n",
    "                                    p = np.ones_like(t)/len(t)\n",
    "                                else: \n",
    "                                    if P_TRAIN:\n",
    "                                        p = train_trial_avg[half_width][subjectID1][condLabel1][stimLabel1][n_loop]\n",
    "                                    else:\n",
    "                                        p = test_trial_avg[half_width][subjectID1][condLabel1][stimLabel1][n_loop]\n",
    "\n",
    "                                if Q_TRAIN:\n",
    "                                    q = train_trial_avg[half_width][subjectID2][condLabel2][stimLabel2][n_loop]\n",
    "                                else:\n",
    "                                    q = test_trial_avg[half_width][subjectID2][condLabel2][stimLabel2][n_loop]\n",
    "\n",
    "                                cost, p_norm, q_norm = coding_cost(\n",
    "                                    np.copy(p), \n",
    "                                    np.copy(q), \n",
    "                                    SMALL_NUMBER=1e-20,\n",
    "                                    SQ_SANITY_CHECK=SQ_SANITY_CHECK,\n",
    "                                    NORM=NORM,\n",
    "                                ) \n",
    "                                results_matrix[i, j] += cost / AVG_LOOPS\n",
    "                                p_norms[i][j] += p_norm / AVG_LOOPS\n",
    "                                q_norms[i][j] += q_norm / AVG_LOOPS\n",
    "\n",
    "                                #print(f'{subjectID1}/{condLabel1}/{stimLabel1} vs. {subjectID2}/{condLabel2}/{stimLabel2}\\t{results_matrix[i, j]}\\t{p}\\t{q}')\n",
    "\n",
    "                        # update after IDs have been calculated above:\n",
    "                        rowLabels.append(f'{subjectID1} / {condLabel1} / {stimLabel1}')\n",
    "\n",
    "                    title = 'Blink Time: {:.3f} ms = {:.2f} qtr note beats @ 100 bpm'.format(\n",
    "                        (2 * half_width / fs)*1000,\n",
    "                        (1/bps) / (2 * half_width / fs),\n",
    "                    )\n",
    "                    title += f'\\nNorm by {NORM}\\n'\n",
    "                    \n",
    "                    if SQ_SANITY_CHECK:\n",
    "                        title += 'coding cost: sq'\n",
    "                    else:\n",
    "                        title += 'coding cost: log'\n",
    "                    title += '\\n'\n",
    "\n",
    "                    if P_BASELINE:\n",
    "                        title += 'p: baseline, $\\sum$p = {:.2f}\\n'.format(sum(p_norm))\n",
    "                    else:\n",
    "                        if P_TRAIN:\n",
    "                            title += f'p [{NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: train'\n",
    "                        else:\n",
    "                            title += f'p [{11-NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: test'\n",
    "                        title += '\\n'\n",
    "                    \n",
    "                    if Q_TRAIN:\n",
    "                        title += f'q [{NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: train'\n",
    "                    else:\n",
    "                        title += f'q [{11-NUM_TRAINING_TRIALS}/11, #avg: {AVG_LOOPS}]: test'\n",
    "                    \n",
    "                    figsize = (N*0.4, N*0.4/2)\n",
    "\n",
    "                    fig, ax = plt.subplots(figsize=figsize)\n",
    "                    plot_info(results_matrix,\n",
    "                            ax, \n",
    "                            rowLabels, colLabels, title, \n",
    "                            vmin = 0,\n",
    "                            vmax=0.05, #10,\n",
    "                            fontsize = 10,\n",
    "                            )\n",
    "                    \n",
    "                    if PLOT_PQ:\n",
    "                        fig, axs = plt.subplots(N, N, figsize=figsize, sharex=True, sharey=True)\n",
    "\n",
    "                        for i in range(N):\n",
    "                            for j in range(N):\n",
    "                                title_str = 'Blink Dur: {:.3f} s'.format(2 * half_width * 1/fs)\n",
    "                                title_str+= f', sub-{subjectID}, {condLabel}, {stimLabel}'\n",
    "                                title_str+= f'\\nTraining Trials\\t(for $p_i$): {trainTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                                title_str+= f'\\nTest Trials\\t(for $q_i$): {testTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                                if SQ_SANITY_CHECK:\n",
    "                                    title_str+= '\\n$ 1/N \\sum (p_i - q_i)^2$ = {:.5f}'.format(results_matrix[i, j])\n",
    "                                else:\n",
    "                                    title_str+= '\\n$-1/N \\sum q_i log p_i + (1-q_i) log (1-p_i)$ = {:.5f}'.format(results_matrix[i, j])\n",
    "\n",
    "                                plot_pq(axs[i][j], p_norms[i][j], q_norms[i][j], t, fs)\n",
    "                        plt.tight_layout()\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PQ = False\n",
    "\n",
    "subjectIDs = [1, 3, 7, 11]\n",
    "half_widths = [13, 26, 53, 106]\n",
    "condLabels = ['Listening', 'Imagery'] #list(train_trial_avg[half_widths[0]][subjectIDs[0]].keys())\n",
    "stimLabels = list(train_trial_avg[half_widths[0]][subjectIDs[0]][condLabels[0]].keys())\n",
    "NORMS = ['sum'] #, 'none'] #['sum'] #, 'max']\n",
    "sq_checks = [False] #[True, False]\n",
    "\n",
    "P_TRAIN = True\n",
    "for SQ_SANITY_CHECK in sq_checks:\n",
    "    for Q_TRAIN in [False]: # [True, False]:\n",
    "        for half_width in half_widths:\n",
    "            for NORM in NORMS:\n",
    "                rowLabels = []\n",
    "                colLabels = []\n",
    "\n",
    "                N = len(subjectIDs)*len(condLabels)*len(stimLabels)\n",
    "                results_matrix = np.zeros(\n",
    "                    shape=(N, N),\n",
    "                )\n",
    "                p_norms = {}\n",
    "                q_norms = {}\n",
    "\n",
    "                i = 0\n",
    "                for i in range(N):\n",
    "                    p_norms[i] = {}\n",
    "                    q_norms[i] = {}\n",
    "\n",
    "                    for j in range(N):\n",
    "                        subjectID1 = subjectIDs[i % len(subjectIDs)] #[int(i / (len(condLabels)*len(stimLabels)))]\n",
    "                        subjectID2 = subjectIDs[j % len(subjectIDs)] #[int(j / (len(condLabels)*len(stimLabels)))]\n",
    "                        condLabel1 = condId_to_State_map[1 + int(i / len(stimLabels))%len(condLabels)]\n",
    "                        condLabel2 = condId_to_State_map[1 + int(j / len(stimLabels))%len(condLabels)]\n",
    "                        stimLabel1 = stimId_to_Song_map[1 + int(i / (len(condLabels)*len(stimLabels)))] #[1 + (i % 4)]\n",
    "                        stimLabel2 = stimId_to_Song_map[1 + int(j / (len(condLabels)*len(stimLabels)))] #[1 + (j % 4)]\n",
    "\n",
    "                        if i == 0:\n",
    "                            colLabels.append(f'{subjectID2} / {condLabel2} / {stimLabel2}')\n",
    "\n",
    "                        if P_TRAIN:\n",
    "                            p = train_trial_avg[half_width][subjectID1][condLabel1][stimLabel1]\n",
    "                        else:\n",
    "                            p = test_trial_avg[half_width][subjectID1][condLabel1][stimLabel1]\n",
    "\n",
    "                        if Q_TRAIN:\n",
    "                            q = train_trial_avg[half_width][subjectID2][condLabel2][stimLabel2]\n",
    "                        else:\n",
    "                            q = test_trial_avg[half_width][subjectID2][condLabel2][stimLabel2]\n",
    "\n",
    "                        results_matrix[i, j], p_norms[i][j], q_norms[i][j] = coding_cost(\n",
    "                            np.copy(p), \n",
    "                            np.copy(q), \n",
    "                            SMALL_NUMBER=1e-20,\n",
    "                            SQ_SANITY_CHECK=SQ_SANITY_CHECK,\n",
    "                            NORM=NORM,\n",
    "                        )\n",
    "\n",
    "                        #print(f'{subjectID1}/{condLabel1}/{stimLabel1} vs. {subjectID2}/{condLabel2}/{stimLabel2}\\t{results_matrix[i, j]}\\t{p}\\t{q}')\n",
    "\n",
    "                    # update after IDs have been calculated above:\n",
    "                    rowLabels.append(f'{subjectID1} / {condLabel1} / {stimLabel1}')\n",
    "\n",
    "                title = 'Blink Time: {:.3f} ms = {:.2f} qtr note beats @ 100 bpm'.format(\n",
    "                    2 * 1000 * half_width * 1/fs,\n",
    "                    (2 * half_width / (bps*fs)),\n",
    "                )\n",
    "                title += f'\\nNorm by {NORM}\\n'\n",
    "                \n",
    "                if SQ_SANITY_CHECK:\n",
    "                    title += 'coding cost: sq'\n",
    "                else:\n",
    "                    title += 'coding cost: log'\n",
    "                title += '\\n'\n",
    "\n",
    "                if P_TRAIN:\n",
    "                    title += f'p [{NUM_TRAINING_TRIALS}/11]: train'\n",
    "                else:\n",
    "                    title += f'p [{11-NUM_TRAINING_TRIALS}/11]: test'\n",
    "                title += '\\n'\n",
    "                \n",
    "                if Q_TRAIN:\n",
    "                    title += f'q [{NUM_TRAINING_TRIALS}/11]: train'\n",
    "                else:\n",
    "                    title += f'q [{11-NUM_TRAINING_TRIALS}/11]: test'\n",
    "                \n",
    "                figsize = (N*.6, .6*N/2)\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=figsize)\n",
    "                plot_info(results_matrix,\n",
    "                          ax, \n",
    "                          rowLabels, colLabels, title, \n",
    "                          #vmax=0.05, #10,\n",
    "                          fontsize = 10,\n",
    "                        )\n",
    "                \n",
    "                if PLOT_PQ:\n",
    "                    fig, axs = plt.subplots(N, N, figsize=figsize, sharex=True, sharey=True)\n",
    "\n",
    "                    for i in range(N):\n",
    "                        for j in range(N):\n",
    "                            title_str = 'Blink Dur: {:.3f} s'.format(2 * half_width * 1/fs)\n",
    "                            title_str+= f', sub-{subjectID}, {condLabel}, {stimLabel}'\n",
    "                            title_str+= f'\\nTraining Trials\\t(for $p_i$): {trainTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                            title_str+= f'\\nTest Trials\\t(for $q_i$): {testTrialIdxs}' # {NUM_TRAINING_TRIALS}'\n",
    "                            if SQ_SANITY_CHECK:\n",
    "                                title_str+= '\\n$ 1/N \\sum (p_i - q_i)^2$ = {:.5f}'.format(results_matrix[i, j])\n",
    "                            else:\n",
    "                                title_str+= '\\n$-1/N \\sum q_i log p_i + (1-q_i) log (1-p_i)$ = {:.5f}'.format(results_matrix[i, j])\n",
    "\n",
    "                            plot_pq(axs[i][j], p_norms[i][j], q_norms[i][j], t, fs)\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9fda837",
   "metadata": {},
   "source": [
    "# Mega Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_widths = list(train_trial_avg.keys())\n",
    "subjectIDs = list(train_trial_avg[half_widths[0]].keys())\n",
    "condLabels = list(train_trial_avg[half_widths[0]][subjectIDs[0]].keys())\n",
    "stimLabels = list(train_trial_avg[half_widths[0]][subjectIDs[0]][condLabels[0]].keys())\n",
    "\n",
    "for half_width in half_widths:\n",
    "\n",
    "    rowLabels = []\n",
    "    colLabels = []\n",
    "\n",
    "    N = len(subjectIDs)*len(condLabels)*len(stimLabels)\n",
    "    results_matrix = np.zeros(\n",
    "        shape=(N, N),\n",
    "    )\n",
    "\n",
    "    i = 0\n",
    "    for i in range(N):\n",
    "\n",
    "        for j in range(N):\n",
    "            subjectID1 = 1 + int(i / (len(condLabels)*len(stimLabels)))\n",
    "            subjectID2 = 1 + int(j / (len(condLabels)*len(stimLabels)))\n",
    "            condLabel1 = condId_to_State_map[1 + int(i / len(stimLabels))%2]\n",
    "            condLabel2 = condId_to_State_map[1 + int(j / len(stimLabels))%2]\n",
    "            stimLabel1 = stimId_to_Song_map[1 + (i % 4)]\n",
    "            stimLabel2 = stimId_to_Song_map[1 + (j % 4)]\n",
    "\n",
    "            if i == 0:\n",
    "                colLabels.append(f'{subjectID2} / {condLabel2} / {stimLabel2}')\n",
    "\n",
    "            p = train_trial_avg[half_width][subjectID1][condLabel1][stimLabel1]\n",
    "            #q = train_trial_avg[half_width][subjectID2][condLabel2][stimLabel2]\n",
    "            q = test_trial_avg[half_width][subjectID2][condLabel2][stimLabel2]\n",
    "\n",
    "            results_matrix[i, j] = coding_cost(\n",
    "                np.copy(p), \n",
    "                np.copy(q), \n",
    "                SMALL_NUMBER=1e-20,\n",
    "                SQ_SANITY_CHECK=False, #True,\n",
    "            )\n",
    "\n",
    "            #print(f'{subjectID1}/{condLabel1}/{stimLabel1} vs. {subjectID2}/{condLabel2}/{stimLabel2}\\t{results_matrix[i, j]}\\t{p}\\t{q}')\n",
    "\n",
    "        rowLabels.append(f'{subjectID1} / {condLabel1} / {stimLabel1}')\n",
    "\n",
    "    title = 'Blink Time: {:.3f} ms = {:.2f} qtr note beats @ 100 bpm'.format(\n",
    "        2 * 1000 * half_width * 1/fs,\n",
    "        (2 * half_width / (bps*fs))\n",
    "    )\n",
    "    plot_info(results_matrix, rowLabels, colLabels, title, \n",
    "              #vmax=10, \n",
    "              figsize = (16, 8),\n",
    "              fontsize = 10,\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6bbabcd",
   "metadata": {},
   "source": [
    "Visualizing log values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2dad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(100)\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(p, label='$p$')\n",
    "plt.plot(1-p, label='$1-p$')\n",
    "plt.legend()\n",
    "plt.ylim([-0.1, 1.1])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(np.log2(p + np.nextafter(0, 1)),\n",
    "         label = '$log_2(p)$')\n",
    "plt.plot(np.log2(1-p),\n",
    "         label = '$log_2(1-p)$')\n",
    "plt.legend()\n",
    "plt.ylim([-10, 1])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(-p * np.log2(p + np.nextafter(0, 1)),\n",
    "         label = '$-p.log_2(p)$')\n",
    "plt.plot(-(1-p) * np.log2(1-p),\n",
    "         label = '$-(1-p)log_2(1-p)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim([-.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffbd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5*np.log2(0.5)*len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b915961",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max((p_i, q_i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ab2e8b5",
   "metadata": {},
   "source": [
    "# (old) Permutations for Null Distros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c532ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LOOPS = 10000\n",
    "NUM_TRIALS = 11\n",
    "TEST_STIM_LABELS = ['chor-038', 'chor-096', 'chor-101', 'chor-019']\n",
    "NOTES_Y_OFFSET = 1\n",
    "\n",
    "PLOT_POINT_CLOUD = False # this takes a lot of memory => slow down\n",
    "\n",
    "LOAD_DISTRO = not True\n",
    "SAVE_DISTRO = not LOAD_DISTRO \n",
    "\n",
    "fs = 64\n",
    "\n",
    "baseline = {} # this will be the null distro\n",
    "test_trial_avg = {}\n",
    "peaks_sq_baseline_distro = {}\n",
    "\n",
    "t = np.arange(start=0, stop=len(cueExp), step=1)\n",
    "\n",
    "plt.figure(figsize = (32, 16))\n",
    "pltIdx = 0\n",
    "\n",
    "rowIdx = 1\n",
    "for subjectID in allTrialsForNullDistro:\n",
    "    if LOAD_DISTRO:\n",
    "        peaks_sq_baseline_distro_samples = np.load(\n",
    "            f\"peaks_sq_baseline_distro_samples_sub{subjectID}_{','.join(condLabels)}_{NUM_LOOPS}.npy\"\n",
    "        )\n",
    "        print(peaks_sq_baseline_distro_samples.shape)\n",
    "\n",
    "    else:\n",
    "        peaks_sq_baseline_distro[subjectID] = []\n",
    "\n",
    "        # Draw NUM_TRIALS from all trials, and loop NUM_LOOPS times\n",
    "        for n in range(NUM_LOOPS):\n",
    "            peaks_sq_baseline = np.zeros_like(t, dtype=np.float64)\n",
    "            \n",
    "            randTrialIdxs = np.random.random_integers(\n",
    "                low=0, \n",
    "                high=len(allTrialsForNullDistro[subjectID]) -1, \n",
    "                size=NUM_TRIALS,\n",
    "            )\n",
    "\n",
    "            for randn in randTrialIdxs: # decide which of 44 trials to draw\n",
    "                #print(randn)\n",
    "                peaks_sq_baseline += allTrialsForNullDistro[subjectID][randn]\n",
    "\n",
    "            peaks_sq_baseline /= NUM_TRIALS # this gives us the average of 11 randomly selected trials\n",
    "            peaks_sq_baseline_distro[subjectID].append(peaks_sq_baseline)\n",
    "\n",
    "        #peaks_sq_baseline_distro_samples = np.empty_like(t) # this adds an extra row?\n",
    "        i = 0\n",
    "        for samples in peaks_sq_baseline_distro[subjectID]:\n",
    "            if i == 0:\n",
    "                peaks_sq_baseline_distro_samples = samples\n",
    "            else:\n",
    "                peaks_sq_baseline_distro_samples = np.vstack(\n",
    "                    (peaks_sq_baseline_distro_samples, samples)\n",
    "                )\n",
    "            i+=1\n",
    "        print(peaks_sq_baseline_distro_samples.shape)\n",
    "\n",
    "        # sort the samples for every time stamp to get the 95% interval\n",
    "        peaks_sq_baseline_distro_samples.sort(axis=0)\n",
    "\n",
    "        # Save to memory!\n",
    "        if SAVE_DISTRO:\n",
    "            np.save(\n",
    "                file=f\"peaks_sq_baseline_distro_samples_sub{subjectID}_{','.join(condLabels)}_{NUM_LOOPS}\",\n",
    "                arr=peaks_sq_baseline_distro_samples,\n",
    "            )\n",
    "\n",
    "    test_trial_avg[subjectID] = {}\n",
    "    for stimLabel in TEST_STIM_LABELS:\n",
    "        pltIdx += 1\n",
    "        ax = plt.subplot(len(allTrialsForNullDistro), 4+1, pltIdx)\n",
    "\n",
    "        # Plot null distro point cloud\n",
    "        if PLOT_POINT_CLOUD:\n",
    "            #for samples in peaks_sq_baseline_distro[subjectID]:\n",
    "            for row in range(peaks_sq_baseline_distro_samples.shape[0]):\n",
    "                line, = ax.plot(\n",
    "                    t/fs, \n",
    "                    peaks_sq_baseline_distro_samples[row], \n",
    "                    '.', \n",
    "                    #label='validation blinks', \n",
    "                    c='k',\n",
    "                    alpha=0.1,\n",
    "                    markersize=.1,\n",
    "                    label = 'Max[null]'\n",
    "                )\n",
    "        else:\n",
    "            max_line, = ax.plot(\n",
    "                t/fs, \n",
    "                peaks_sq_baseline_distro_samples[-1, :], \n",
    "                '.', \n",
    "                #label='validation blinks', \n",
    "                c='k',\n",
    "                alpha=0.1,\n",
    "                #markersize=.1,\n",
    "            )\n",
    "\n",
    "\n",
    "        # Plot null distro CI intervals\n",
    "        null_distro_95 = peaks_sq_baseline_distro_samples[int(.95*NUM_LOOPS), :]\n",
    "\n",
    "        null_line, = ax.plot(\n",
    "            t/fs, \n",
    "            null_distro_95, \n",
    "            #marker = '_',\n",
    "            #ls = '', \n",
    "            #label='validation blinks', \n",
    "            c='c',\n",
    "            #alpha=0.1,\n",
    "        )\n",
    "\n",
    "        ax.fill_between(\n",
    "            t/fs, \n",
    "            peaks_sq_baseline_distro_samples[int(.95*NUM_LOOPS), :], \n",
    "            0, \n",
    "            color=null_line.get_color(), \n",
    "            alpha=.3,\n",
    "            label = 'Null Distribution'\n",
    "        )\n",
    "\n",
    "        test_trial_avg[subjectID][stimLabel] = np.zeros_like(t, dtype=np.float64)\n",
    "\n",
    "        notes = t[stim[stimLabel]['notes']]\n",
    "        beats = t[stim[stimLabel]['beats']>0]\n",
    "        \n",
    "        for condLabel in condLabels:\n",
    "\n",
    "            for trialIdx in peaks_sq_all[subjectID][stimLabel][condLabel]:\n",
    "                val_peaks_sq = peaks_sq_all[subjectID][stimLabel][condLabel][trialIdx]\n",
    "                test_trial_avg[subjectID][stimLabel] += val_peaks_sq\n",
    "                \n",
    "            test_trial_avg[subjectID][stimLabel] /= len(peaks_sq_all[subjectID][stimLabel][condLabel])\n",
    "\n",
    "            test_distro = test_trial_avg[subjectID][stimLabel]\n",
    "\n",
    "            avg_line, = ax.plot(\n",
    "                t/fs, \n",
    "                test_distro, \n",
    "                #'.', \n",
    "                #label=f'Trial avg. for {stimLabel}', \n",
    "                c='r',\n",
    "                #alpha=0.1,\n",
    "            )\n",
    "\n",
    "            ax.fill_between(\n",
    "                t/fs, \n",
    "                test_distro, \n",
    "                0, \n",
    "                color=avg_line.get_color(), \n",
    "                alpha=.3,\n",
    "                label=f'Trial avg. for {stimLabel}', \n",
    "            )\n",
    "\n",
    "            significant_samples = (test_distro - null_distro_95) > 0\n",
    "\n",
    "            sig_line, = ax.plot(\n",
    "                t/fs,\n",
    "                significant_samples,\n",
    "                color = 'yellow',\n",
    "                alpha = 0.3,\n",
    "            )\n",
    "            ax.fill_between(\n",
    "                t/fs, \n",
    "                significant_samples, \n",
    "                0, \n",
    "                color=sig_line.get_color(), \n",
    "                label = 'Test > 95%ile of null',\n",
    "                alpha=.3,\n",
    "            )\n",
    "\n",
    "            score = 100 * np.sum(significant_samples) / len(significant_samples)\n",
    "\n",
    "        ax.plot(t[notes]/fs, 0*t[notes] + NOTES_Y_OFFSET, '.', label='notes')\n",
    "        beat_dots, = ax.plot(t[beats]/fs, 0*t[beats] + NOTES_Y_OFFSET, 'o', label='beats')\n",
    "        for beat in beats:\n",
    "            ax.axvline(\n",
    "                x=t[beat]/fs, \n",
    "                ls='-', # solid line\n",
    "                alpha=0.2, \n",
    "                c=beat_dots.get_color()\n",
    "            )\n",
    "\n",
    "        #ax_base = ax.twinx()\n",
    "        #ax_base.plot(t/fs, peaks_sq_baseline, label='baseline') #, c=line.get_color())\n",
    "        \n",
    "        title_str = f'Subject{subjectID} | {condLabel} | {stimLabel} vs. Null'\n",
    "        title_str+= f'\\n#Trials Per Avg: {NUM_TRIALS} | #Loops: {NUM_LOOPS}'\n",
    "        title_str+= '\\nTest > Null for {:.2f}% time'.format(score)\n",
    "        ax.set_title(title_str)\n",
    "\n",
    "        ax.set_xlabel('Time [s]')\n",
    "        ax.set_ylim([-.1, 1.1])\n",
    "\n",
    "        if (pltIdx % 5) == 1: # first column\n",
    "            ax.legend(loc='upper right', bbox_to_anchor=[-0.1, 1])\n",
    "\n",
    "        # Plot the significance curves for all songs in the last column\n",
    "        axLastCol = plt.subplot(\n",
    "            len(allTrialsForNullDistro), # nrows = no. of subjects\n",
    "            4+1, # cols = no. of songs + one \"bar codes\" plot\n",
    "            5*rowIdx, # select the last column of this row\n",
    "        )\n",
    "        sig_line, = axLastCol.plot(\n",
    "            t/fs,\n",
    "            significant_samples + int(stimLabel_to_sheet_order_map[stimLabel]),\n",
    "            #color = 'yellow',\n",
    "            label = stimLabel,\n",
    "            #alpha = 0.3,\n",
    "        )\n",
    "\n",
    "        if 0: # overlay score images\n",
    "            bar = 2 * (stimLabel_to_sheet_order_map[stimLabel] -1)\n",
    "            # https://stackoverflow.com/questions/61169982/set-location-of-image-in-matplotlib\n",
    "            image_artist = axLastCol.imshow(imgs[bar])\n",
    "\n",
    "            if bar == 4: # 8 measures\n",
    "                SCALE = 1803/fs #* 8/12.\n",
    "            else: # 9 measures\n",
    "                SCALE = 1803/fs #* 9/12.\n",
    "\n",
    "            SCALE /= imgs[bar].shape[0]\n",
    "            image_artist.set_extent(np.array(image_artist.get_extent())/SCALE)\n",
    "            transform = mpl.transforms.Affine2D().translate(0, stimLabel_to_sheet_order_map[stimLabel])\n",
    "            image_artist.set_transform(transform + axLastCol.transData)\n",
    "\n",
    "        #ax_base.legend(loc='upper right', bbox_to_anchor=[1.3, 1])\n",
    "\n",
    "    axLastCol.set_ylim([5, 0]) # flip axis to go top to bottom in song order of sheet music\n",
    "    axLastCol.set_yticks(ticks=[1, 2, 3, 4], labels=['chor-038', 'chor-096', 'chor-101', 'chor-019'])\n",
    "    #axLastCol.legend(loc='upper right')\n",
    "    axLastCol.set_ylabel('Song #')\n",
    "    axLastCol.set_xlabel('Time [s]')\n",
    "    axLastCol.set_title(f'Subject{subjectID} | {condLabel} | Blink Avg > Null')\n",
    "\n",
    "    pltIdx += 1 # since we already plotted the last column (bar codes)\n",
    "    rowIdx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.savefig(f'subs{len(allTrialsForNullDistro)}_{condLabel}_nullLoops{NUM_LOOPS}.png',\n",
    "            format='png',\n",
    "            dpi = 200,\n",
    "            )\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4db12cab",
   "metadata": {},
   "source": [
    "# Odd and Even Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb913b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LOOPS = 10000 #10000\n",
    "NUM_TRIALS = 11\n",
    "TEST_STIM_LABELS = ['chor-038', 'chor-096', 'chor-101', 'chor-019']\n",
    "NOTES_Y_OFFSET = 1\n",
    "\n",
    "PLOT_POINT_CLOUD = False # this takes a lot of memory => slow down\n",
    "\n",
    "LOAD_DISTRO = not True\n",
    "SAVE_DISTRO = not LOAD_DISTRO \n",
    "\n",
    "fs = 64\n",
    "\n",
    "cond_trials = range(len(allTrialsForNullDistro[subjectID])) # this should be handled per subject if trials are dropped\n",
    "split_trials_odd = [i for i in cond_trials if i%2==1]\n",
    "split_trials_even = [i for i in cond_trials if i%2==0]\n",
    "\n",
    "baseline = {} # this will be the null distro\n",
    "test_trial_avg = {}\n",
    "peaks_sq_baseline_distro = {}\n",
    "\n",
    "t = np.arange(start=0, stop=len(cueExp), step=1)\n",
    "\n",
    "plt.figure(figsize = (32, 16))\n",
    "\n",
    "for split in ['even']: #, 'odd']:\n",
    "    if split == 'odd':\n",
    "        split_trials = split_trials_odd\n",
    "    else:\n",
    "        split_trials = split_trials_even\n",
    "    \n",
    "    pltIdx = 0\n",
    "    rowIdx = 1\n",
    "\n",
    "    for subjectID in allTrialsForNullDistro:\n",
    "        \n",
    "        if LOAD_DISTRO:\n",
    "            peaks_sq_baseline_distro_samples = np.load(\n",
    "                f\"peaks_sq_baseline_distro_samples_sub{subjectID}_{','.join(condLabels)}_{NUM_LOOPS}_{split}.npy\"\n",
    "            )\n",
    "            print(peaks_sq_baseline_distro_samples.shape)\n",
    "\n",
    "        else:\n",
    "            peaks_sq_baseline_distro[subjectID] = []\n",
    "\n",
    "            # Draw NUM_TRIALS from all trials, and loop NUM_LOOPS times\n",
    "            for n in range(NUM_LOOPS):\n",
    "                peaks_sq_baseline = np.zeros_like(t, dtype=np.float64)\n",
    "                \n",
    "                randTrialIdxs = np.random.choice(\n",
    "                    split_trials,\n",
    "                    size=NUM_TRIALS,\n",
    "                )\n",
    "                #print(randTrialIdxs)\n",
    "\n",
    "                for randn in randTrialIdxs: # decide which of 44 trials to draw\n",
    "                    #print(randn)\n",
    "                    peaks_sq_baseline += allTrialsForNullDistro[subjectID][randn]\n",
    "\n",
    "                peaks_sq_baseline /= NUM_TRIALS # this gives us the average of 11 randomly selected trials\n",
    "                peaks_sq_baseline_distro[subjectID].append(peaks_sq_baseline)\n",
    "\n",
    "            #peaks_sq_baseline_distro_samples = np.empty_like(t) # this adds an extra row?\n",
    "            i = 0\n",
    "            for samples in peaks_sq_baseline_distro[subjectID]:\n",
    "                if i == 0:\n",
    "                    peaks_sq_baseline_distro_samples = samples\n",
    "                else:\n",
    "                    peaks_sq_baseline_distro_samples = np.vstack(\n",
    "                        (peaks_sq_baseline_distro_samples, samples)\n",
    "                    )\n",
    "                i+=1\n",
    "            print(peaks_sq_baseline_distro_samples.shape)\n",
    "\n",
    "            # sort the samples for every time stamp to get the 95% interval\n",
    "            peaks_sq_baseline_distro_samples.sort(axis=0)\n",
    "\n",
    "            # Save to memory!\n",
    "            if SAVE_DISTRO:\n",
    "                np.save(\n",
    "                    file=f\"peaks_sq_baseline_distro_samples_sub{subjectID}_{','.join(condLabels)}_{NUM_LOOPS}_{split}\",\n",
    "                    arr=peaks_sq_baseline_distro_samples,\n",
    "                )\n",
    "\n",
    "        test_trial_avg[subjectID] = {}\n",
    "        for stimLabel in TEST_STIM_LABELS:\n",
    "            pltIdx += 1\n",
    "            ax = plt.subplot(len(allTrialsForNullDistro), 4+1, pltIdx)\n",
    "\n",
    "            # Plot null distro point cloud\n",
    "            if PLOT_POINT_CLOUD:\n",
    "                #for samples in peaks_sq_baseline_distro[subjectID]:\n",
    "                for row in range(peaks_sq_baseline_distro_samples.shape[0]):\n",
    "                    line, = ax.plot(\n",
    "                        t/fs, \n",
    "                        peaks_sq_baseline_distro_samples[row], \n",
    "                        '.', \n",
    "                        #label='validation blinks', \n",
    "                        c='k',\n",
    "                        alpha=0.1,\n",
    "                        markersize=.1,\n",
    "                    )\n",
    "            else:\n",
    "                max_line, = ax.plot(\n",
    "                    t/fs, \n",
    "                    peaks_sq_baseline_distro_samples[-1, :], \n",
    "                    '.', \n",
    "                    #label='validation blinks', \n",
    "                    c='k',\n",
    "                    alpha=0.1,\n",
    "                    #markersize=.1,\n",
    "                    label = 'Max[null]'\n",
    "                )\n",
    "\n",
    "            # Plot null distro CI intervals\n",
    "            null_distro_95 = peaks_sq_baseline_distro_samples[int(.95*NUM_LOOPS), :]\n",
    "\n",
    "            null_line, = ax.plot(\n",
    "                t/fs, \n",
    "                null_distro_95, \n",
    "                #marker = '_',\n",
    "                #ls = '', \n",
    "                #label='validation blinks', \n",
    "                c='c',\n",
    "                #alpha=0.1,\n",
    "            )\n",
    "\n",
    "            ax.fill_between(\n",
    "                t/fs, \n",
    "                peaks_sq_baseline_distro_samples[int(.95*NUM_LOOPS), :], \n",
    "                0, \n",
    "                color=null_line.get_color(), \n",
    "                alpha=.3,\n",
    "                label = 'Null Distribution'\n",
    "            )\n",
    "\n",
    "            test_trial_avg[subjectID][stimLabel] = np.zeros_like(t, dtype=np.float64)\n",
    "\n",
    "            notes = t[stim[stimLabel]['notes']]\n",
    "            beats = t[stim[stimLabel]['beats']>0]\n",
    "            \n",
    "            for condLabel in condLabels:\n",
    "                Navg = 0\n",
    "                for trialIdx in peaks_sq_all[subjectID][stimLabel][condLabel]:\n",
    "                    if trialIdx in split_trials:\n",
    "                        Navg += 1\n",
    "                        val_peaks_sq = peaks_sq_all[subjectID][stimLabel][condLabel][trialIdx]\n",
    "                        test_trial_avg[subjectID][stimLabel] += val_peaks_sq\n",
    "                    \n",
    "                test_trial_avg[subjectID][stimLabel] /= Navg #len(peaks_sq_all[subjectID][stimLabel][condLabel])\n",
    "\n",
    "                test_distro = test_trial_avg[subjectID][stimLabel]\n",
    "\n",
    "                avg_line, = ax.plot(\n",
    "                    t/fs, \n",
    "                    test_distro, \n",
    "                    #'.', \n",
    "                    #label=f'Trial avg. for {stimLabel}', \n",
    "                    c='r',\n",
    "                    #alpha=0.1,\n",
    "                )\n",
    "\n",
    "                ax.fill_between(\n",
    "                    t/fs, \n",
    "                    test_distro, \n",
    "                    0, \n",
    "                    color=avg_line.get_color(), \n",
    "                    alpha=.3,\n",
    "                    label=f'Trial avg. for {stimLabel}', \n",
    "                )\n",
    "\n",
    "                significant_samples = (test_distro - null_distro_95) > 0\n",
    "\n",
    "                sig_line, = ax.plot(\n",
    "                    t/fs,\n",
    "                    significant_samples,\n",
    "                    color = 'yellow',\n",
    "                    alpha = 0.3,\n",
    "                )\n",
    "                ax.fill_between(\n",
    "                    t/fs, \n",
    "                    significant_samples, \n",
    "                    0, \n",
    "                    color=sig_line.get_color(), \n",
    "                    label = 'Test > 95%ile of null',\n",
    "                    alpha=.3,\n",
    "                )\n",
    "\n",
    "                score = 100 * np.sum(significant_samples) / len(significant_samples)\n",
    "\n",
    "            ax.plot(t[notes]/fs, 0*t[notes] + NOTES_Y_OFFSET, '.', label='notes')\n",
    "            beat_dots, = ax.plot(t[beats]/fs, 0*t[beats] + NOTES_Y_OFFSET, 'o', label='beats')\n",
    "            for beat in beats:\n",
    "                ax.axvline(\n",
    "                    x=t[beat]/fs, \n",
    "                    ls='-', # solid line\n",
    "                    alpha=0.2, \n",
    "                    c=beat_dots.get_color()\n",
    "                )\n",
    "\n",
    "            #ax_base = ax.twinx()\n",
    "            #ax_base.plot(t/fs, peaks_sq_baseline, label='baseline') #, c=line.get_color())\n",
    "            \n",
    "            title_str = f'Subject{subjectID} | {condLabel} | {stimLabel} vs. Null'\n",
    "            title_str+= f'\\n#Trials Per Avg: {NUM_TRIALS} | #Loops: {NUM_LOOPS} | {split}'\n",
    "            title_str+= '\\nTest > Null for {:.2f}% time'.format(score)\n",
    "            ax.set_title(title_str)\n",
    "\n",
    "            ax.set_xlabel('Time [s]')\n",
    "            ax.set_ylim([-.1, 1.1])\n",
    "\n",
    "            if (pltIdx % 5) == 1: # first column\n",
    "                ax.legend(loc='upper right', bbox_to_anchor=[-0.1, 1])\n",
    "\n",
    "            # Plot the significance curves for all songs in the last column\n",
    "            axLastCol = plt.subplot(\n",
    "                len(allTrialsForNullDistro), # nrows = no. of subjects\n",
    "                4+1, # cols = no. of songs + one \"bar codes\" plot\n",
    "                5*rowIdx, # select the last column of this row\n",
    "            )\n",
    "            sig_line, = axLastCol.plot(\n",
    "                t/fs,\n",
    "                significant_samples + int(stimLabel_to_sheet_order_map[stimLabel]),\n",
    "                #color = 'yellow',\n",
    "                label = stimLabel,\n",
    "                #alpha = 0.3,\n",
    "            )\n",
    "\n",
    "            if 0: # overlay score images\n",
    "                bar = 2 * (stimLabel_to_sheet_order_map[stimLabel] -1)\n",
    "                # https://stackoverflow.com/questions/61169982/set-location-of-image-in-matplotlib\n",
    "                image_artist = axLastCol.imshow(imgs[bar])\n",
    "\n",
    "                if bar == 4: # 8 measures\n",
    "                    SCALE = 1803/fs #* 8/12.\n",
    "                else: # 9 measures\n",
    "                    SCALE = 1803/fs #* 9/12.\n",
    "\n",
    "                SCALE /= imgs[bar].shape[0]\n",
    "                image_artist.set_extent(np.array(image_artist.get_extent())/SCALE)\n",
    "                transform = mpl.transforms.Affine2D().translate(0, stimLabel_to_sheet_order_map[stimLabel])\n",
    "                image_artist.set_transform(transform + axLastCol.transData)\n",
    "\n",
    "            #ax_base.legend(loc='upper right', bbox_to_anchor=[1.3, 1])\n",
    "\n",
    "        axLastCol.set_ylim([5, 0]) # flip axis to go top to bottom in song order of sheet music\n",
    "        axLastCol.set_yticks(ticks=[1, 2, 3, 4], labels=['chor-038', 'chor-096', 'chor-101', 'chor-019'])\n",
    "        #axLastCol.legend(loc='upper right')\n",
    "        axLastCol.set_ylabel('Song #')\n",
    "        axLastCol.set_xlabel('Time [s]')\n",
    "        axLastCol.set_title(f'Subject{subjectID} | {condLabel} | Blink Avg > Null')\n",
    "\n",
    "        pltIdx += 1 # since we already plotted the last column (bar codes)\n",
    "        rowIdx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "            \n",
    "    plt.savefig(f'subs{len(allTrialsForNullDistro)}_{condLabel}_nullLoops{NUM_LOOPS}_{split}.png',\n",
    "                format='png',\n",
    "                dpi = 200,\n",
    "                )\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distro_95 = peaks_sq_baseline_distro_samples[int(.95*NUM_LOOPS), :]\n",
    "test_distro = test_trial_avg[subjectID][stimLabel]\n",
    "\n",
    "plt.figure(figsize = (9,4))\n",
    "plt.plot(null_distro_95)\n",
    "plt.plot(test_distro, ':')\n",
    "plt.plot((test_distro - null_distro_95) > 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1accd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trial_avg[subjectID][stimLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6339d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
